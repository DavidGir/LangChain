{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Stores\n",
    "\n",
    "After document loading and doc/ text splitting, we create embeddings of those documents and store them in a vector store. A vector store is a database where we can easily look up similar vectors when trying to find documents relevant to the question at hand. We can then take the question at hand, create an embedding, and then do comparisons to all the different vectors in the vector store and pick the n most similar. We then take those n most similar chunks, and pass them along with the question into an LLM and get back an answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"../public/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"../public/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"../public/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"../public/cs229_lectures/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings \n",
    "\n",
    "Let's take the splits and embed them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First two sentences are very similar and the third one is not related\n",
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then use embedding class to create an embedding for each sentence:\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use NumPy to compare the similarity between the embeddings:\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631227500523609"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As expected the first two embeddings have a high similarity score:\n",
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7703257495981695"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we compare the first and the third embedding, we get a lower similarity score:\n",
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7591627401108028"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we compare the second and the third embedding, we also get a lower similarity score:\n",
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma is lightweight and in-memory vector db which makes it easy to get up and started with.\n",
    "# Hosted solutions such as pinecone is great for larger sets of data.\n",
    "#! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "# Chroma specific keyword argument to persist the embeddings to disk:\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just making sure nothing is there\n",
    "!rm -rf ./docs/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "# If we take a look at the collection count we can see its the same number of splits as we had above:\n",
    "print(vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return 3 documents that are most similar to the question:\t\n",
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \n",
      "rather than sending us email individually, if you send email to this account, it will \n",
      "actually let us get back to you maximally quickly with answers to your questions.  \n",
      "If you're asking questions about homework probl ems, please say in the subject line which \n",
      "assignment and which question the email refers to, since that will also help us to route \n",
      "your question to the appropriate TA or to me  appropriately and get the response back to \n",
      "you quickly.  \n",
      "Let's see. Skipping ahead — let's see — for homework, one midterm, one open and term \n",
      "project. Notice on the honor code. So one thi ng that I think will help you to succeed and \n",
      "do well in this class and even help you to enjoy this cla ss more is if you form a study \n",
      "group.  \n",
      "So start looking around where you' re sitting now or at the end of class today, mingle a \n",
      "little bit and get to know your classmates. I strongly encourage you to form study groups \n",
      "and sort of have a group of people to study with and have a group of your fellow students \n",
      "to talk over these concepts with. You can also  post on the class news group if you want to \n",
      "use that to try to form a study group.  \n",
      "But some of the problems sets in this cla ss are reasonably difficult.  People that have \n",
      "taken the class before may tell you they were very difficult. And just I bet it would be \n",
      "more fun for you, and you'd probably have a be tter learning experience if you form a\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets save this and use it later:\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure modes\n",
    "\n",
    "This seems great, and basic similarity search will get you 80% of the way there very easily.\n",
    "\n",
    "But there are some failure modes that can creep up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that we are getting duplicate chunks (because of the duplicate `MachineLearning-Lecture01.pdf` in the index).\n",
    "Semantic search fetches all similar documents, but does not enforce diversity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': '../public/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 2, 'source': '../public/cs229_lectures/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 14, 'source': '../public/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 4, 'source': '../public/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': '../public/cs229_lectures/MachineLearning-Lecture02.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# As we loop through the docs metadata we can see a new failure mode. The questions asks about the third lecture but the first document is from the third lecture but the search includes results from other lectures as well.\n",
    "# It is picking up on the word regression but seems to be ignoring the third lecture part of the question.\n",
    "# It's not querying on the third lecture part of the question due to the fact that it is a piece of structured information that isn't really perfectly captured in the semantic embedding.\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "really makes a difference between a good so lution and amazing solution. And to give \n",
      "everyone to just how we do points assignments, or what is it that causes a solution to get \n",
      "full marks, or just how to write amazing so lutions. Becoming a grad er is usually a good \n",
      "way to do that.  \n",
      "Graders are paid positions and you also get free  food, and it's usually fun for us to sort of \n",
      "hang out for an evening and grade all the a ssignments. Okay, so I will send email. So \n",
      "don't email me yet if you want to be a grader. I'll send email to the entire class later with \n",
      "the administrative details and to solicit app lications. So you can email us back then, to \n",
      "apply, if you'd be interested in being a grader.  \n",
      "Okay, any questions about that? All right, okay, so let's get started with today's material. \n",
      "So welcome back to the second lecture. What  I want to do today is talk about linear \n",
      "regression, gradient descent, and the norma l equations. And I should also say, lecture \n",
      "notes have been posted online and so if some  of the math I go over today, I go over rather \n",
      "quickly, if you want to see every equation wr itten out and work through the details more \n",
      "slowly yourself, go to the course homepage and download detailed lecture notes that \n",
      "pretty much describe all the mathematical, te chnical contents I'm going to go over today.  \n",
      "Today, I'm also going to delve into a fair amount  – some amount of linear algebra, and so\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
